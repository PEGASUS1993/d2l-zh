# 循环神经网络
:label:`chap_rnn`

到目前为止，我们遇到了两种类型的数据：表格数据和图像数据。对于后者，我们设计了专门的层，以利用它们的规律性。换句话说，如果我们要在图像中嵌入像素，那么就更难推理它的内容，看起来很像模拟电视时代测试模式背景的内容。

最重要的是，到目前为止，我们默示假设我们的数据都是从一些分布中提取的，并且所有的例子都是独立和相同的分布（即）。不幸的是，对于大多数数据来说，情况并非如此。例如，本段中的词是按顺序编写的，如果随机排列，很难解释其含义。同样，视频中的图像帧、对话中的音频信号以及网站上的浏览行为都遵循顺序。因此，可以合理地假定，这些数据的专门模型在描述这些数据方面会更好。

另一个问题是因为我们可能不仅接收序列作为输入，而且可能会期望继续这一序列。例如，任务可能是继续系列 $2, 4, 6, 8, 10, \ldots$ 这是相当常见的时间序列分析, 预测股市, 病人的发烧曲线, 或赛车所需的加速度.我们再次希望拥有可以处理这些数据的模型。

简而言之，虽然 CNNs 可以有效地处理空间信息，但 **循环神经网络** (RNNs) 旨在更好地处理序列化的信息。RNN 引入状态变量来存储过去的信息，并用其与当前的输入共同决定当前的输出。

许多使用循环网络的例子都是基于文本数据的。因此，我们将在本章中强调语言模型。在对序列数据进行更正式的审查之后，我们介绍了预处理文本数据的实用技术。接下来，我们将讨论语言模型的基本概念，并以此讨论作为 RNNs 设计的灵感。最后，我们介绍了 RNNs 的梯度计算方法，以探讨在训练这些网络时可能遇到的问题。

```toc
:maxdepth: 2

sequence
text-preprocessing
language-models-and-dataset
rnn
rnn-scratch
rnn-concise
bptt
```
